from fastapi import FastAPI
from pydantic import BaseModel
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import torch.nn.functional as F
import pickle
import requests
import os

# ğŸŒ Hugging Face model adÄ±
HF_MODEL_ID = "Kahsi13/tomato-bert-10"
LABEL_ENCODER_URL = "https://huggingface.co/Kahsi13/tomato-bert-10/resolve/main/label_encoder.pkl"

# ğŸš€ Uygulama
app = FastAPI()

# ğŸ§  Model ve tokenizer
tokenizer = AutoTokenizer.from_pretrained(HF_MODEL_ID)
model = AutoModelForSequenceClassification.from_pretrained(HF_MODEL_ID)
model.eval()

# ğŸ·ï¸ Label encoder'Ä± indir ve yÃ¼kle
encoder_path = "label_encoder.pkl"
if not os.path.exists(encoder_path):
    with open(encoder_path, "wb") as f:
        f.write(requests.get(LABEL_ENCODER_URL).content)

with open(encoder_path, "rb") as f:
    label_encoder = pickle.load(f)

# ğŸ“¥ API giriÅŸ formatÄ±
class InputText(BaseModel):
    text: str

# ğŸ  Ana endpoint
@app.get("/")
def read_root():
    return {"message": "Tomato Disease BERT API is running."}

# ğŸ” Tahmin endpoint'i
@app.post("/predict")
def predict(input: InputText):
    inputs = tokenizer(input.text, return_tensors="pt", truncation=True, padding=True)
    with torch.no_grad():
        outputs = model(**inputs)
        probs = F.softmax(outputs.logits, dim=1)
        pred_id = torch.argmax(probs, dim=1).item()
        confidence = torch.max(probs).item()
        label = label_encoder.inverse_transform([pred_id])[0]
    return {"label": label, "confidence": round(confidence, 4)}